# AI-Ethics-Deepfake-Research
Title: ‚ÄúThe Dark Side of Innovation: Exploring AI Ethics and The Rise of Deepfakes‚Äù 

Author: Somya Agrawal  
Duration: June 2025 ‚Äì July 20245 
Institution: Gyan Ganga Institute of Technology and Sciences, Jabalpur (M.P.)    

## Overview
This repository presents the findings of my research project on **AI Ethics and Deepfake Technology**.  
The study was conducted using a structured **15-questionnaire survey** to understand public awareness, risks, and perceptions surrounding deepfake technology.  

---

## Objective
The primary goal of this research was:

1. To assess public awareness and understanding of deepfake technology. 
2. To identify the sectors most vulnerable to deepfake manipulations. 
3. To analyse the ethical concerns surrounding the creation and distribution of deepfakes. 
4. To explore the role of AI ethics in responsible content generation. 
5. To evaluate current legal frameworks addressing deepfake misuse. 
6. To suggest ethical guidelines and regulatory approaches for AI-generated media.

---
   
## Key Findings
- **76%** of respondents are aware of the term *deepfake*.  
- **88%** have encountered a deepfake video or image at least once.  
- **76%** consider **spreading misinformation** as the primary risk of deepfakes.  
- **54%** see the **media and journalism sector** as most vulnerable to misuse.  
- **94%** report that deepfakes have reduced their trust in digital media.  
- **60%** believe current laws address AI and deepfakes either *very well* or *somewhat well*.  
- **46%** think technology companies should regulate deepfakes, while **36%** support government oversight.  
- **90%** support **legal punishment** for harmful deepfakes.  
- **84%** agree individuals should have the right to sue if their face/voice is misused.  
- **92%** support **labelling AI-generated content** consistently.  
- **68%** believe AI tools should be restricted or supervised.  
- **74%** support **mandatory ethical training** for AI developers.  
- **84%** think AI can act ethically if supervised by humans.  
- Only **2%** believe AI tools should be unrestricted.

---

## Conclusion
The findings indicate a **high level of public awareness** of deepfakes but also significant concerns around **misinformation, misuse, and lack of trust in digital media**.  
There is strong public demand for:
- **Stricter regulation and oversight** (both government and technology companies)  
- **Legal accountability** for harmful use  
- **Transparency and labelling** of AI-generated content  
- **Ethical training and supervision** in AI development

This study highlights the urgent need for **balanced policies and frameworks** to ensure the ethical use of AI while protecting society from the potential harms of deepfake technology.  

---

## Repository Contents
-  `README.md` ‚Üí Project overview (this file)
-  [Click here to view the research report]()

---

## Connect with Me

üîó [LinkedIn](https://www.linkedin.com/in/somya-agrawal-analyst/)  
üìß somya.agrawal936@email.com

